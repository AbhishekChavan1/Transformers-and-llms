{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch sentence-transformers datasets -q\n",
        "!pip install mteb faiss-cpu sentence-transformers -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhkVbgRtPEJP",
        "outputId": "8a96e6cb-cdb7-41e3-a589-7b9530d590df"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.8/304.8 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# Step 2: Imports and the Corrected, Definitive Custom Model\n",
        "# ==============================================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoModel, AutoTokenizer, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.stats import spearmanr\n",
        "import numpy as np\n",
        "from typing import Optional, List, Dict, Any\n",
        "import logging\n",
        "from dataclasses import dataclass\n",
        "import json\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "print(\"Libraries installed and imported successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xemdzgWYPGGK",
        "outputId": "f86061df-645b-4aae-92b4-e71a0ffa3538"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries installed and imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class ModelConfig:\n",
        "    \"\"\"Configuration for custom BGE model\"\"\"\n",
        "    model_name: str = \"BAAI/bge-small-en-v1.5\"  # Base BGE model\n",
        "    hidden_size: int = 384\n",
        "    projection_dim: int = 768\n",
        "    num_layers_to_average: int = 4\n",
        "    pooling_strategy: str = \"mean\"  # \"cls\", \"mean\", \"attention\"\n",
        "    use_projection_head: bool = True\n",
        "    dropout_rate: float = 0.1\n",
        "    activation: str = \"gelu\""
      ],
      "metadata": {
        "id": "5L-WtDgpi8-j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ProjectionHead(nn.Module):\n",
        "    \"\"\"Projection head with L2 normalization\"\"\"\n",
        "    def __init__(self, input_dim: int, hidden_dim: int, output_dim: int,\n",
        "                 activation: str = \"gelu\", dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.projection = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            self._get_activation(activation),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden_dim, output_dim)\n",
        "        )\n",
        "\n",
        "    def _get_activation(self, activation: str):\n",
        "        activations = {\n",
        "            \"relu\": nn.ReLU(),\n",
        "            \"gelu\": nn.GELU(),\n",
        "            \"tanh\": nn.Tanh(),\n",
        "            \"silu\": nn.SiLU()\n",
        "        }\n",
        "        return activations.get(activation, nn.GELU())\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        projected = self.projection(x)\n",
        "        # L2 normalization\n",
        "        return F.normalize(projected, p=2, dim=-1)"
      ],
      "metadata": {
        "id": "3T6AXu3Ri9gE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionPooling(nn.Module):\n",
        "    \"\"\"Attention-based pooling mechanism\"\"\"\n",
        "    def __init__(self, hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.attention_weights = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "        # hidden_states: [batch_size, seq_len, hidden_size]\n",
        "        # attention_mask: [batch_size, seq_len]\n",
        "\n",
        "        # Compute attention scores\n",
        "        attention_scores = self.attention_weights(hidden_states).squeeze(-1)  # [batch_size, seq_len]\n",
        "\n",
        "        # Mask out padding tokens\n",
        "        attention_scores = attention_scores.masked_fill(attention_mask == 0, float('-inf'))\n",
        "\n",
        "        # Apply softmax\n",
        "        attention_weights = F.softmax(attention_scores, dim=-1)  # [batch_size, seq_len]\n",
        "\n",
        "        # Weighted sum\n",
        "        pooled = torch.sum(hidden_states * attention_weights.unsqueeze(-1), dim=1)\n",
        "        return pooled\n"
      ],
      "metadata": {
        "id": "_cOQKWPQjB5G"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerwiseWeightedSum(nn.Module):\n",
        "    \"\"\"Weighted sum of multiple layers\"\"\"\n",
        "    def __init__(self, num_layers: int, learnable: bool = True):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.learnable = learnable\n",
        "\n",
        "        if learnable:\n",
        "            # Initialize with equal weights\n",
        "            self.layer_weights = nn.Parameter(torch.ones(num_layers) / num_layers)\n",
        "        else:\n",
        "            self.register_buffer('layer_weights', torch.ones(num_layers) / num_layers)\n",
        "\n",
        "    def forward(self, layer_outputs: List[torch.Tensor]) -> torch.Tensor:\n",
        "        # layer_outputs: List of tensors [batch_size, seq_len, hidden_size]\n",
        "        if self.learnable:\n",
        "            weights = F.softmax(self.layer_weights, dim=0)\n",
        "        else:\n",
        "            weights = self.layer_weights\n",
        "\n",
        "        weighted_sum = torch.zeros_like(layer_outputs[0])\n",
        "        for i, layer_output in enumerate(layer_outputs):\n",
        "            weighted_sum += weights[i] * layer_output\n",
        "\n",
        "        return weighted_sum"
      ],
      "metadata": {
        "id": "QgGzjm70jFBy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBGEModel(nn.Module):\n",
        "    \"\"\"Custom BGE model with enhanced features\"\"\"\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        # Load base BGE model\n",
        "        self.backbone = AutoModel.from_pretrained(config.model_name)\n",
        "        self.backbone.config.output_hidden_states = True\n",
        "\n",
        "        # Get actual hidden size from model\n",
        "        actual_hidden_size = self.backbone.config.hidden_size\n",
        "\n",
        "        # Layerwise weighted sum\n",
        "        self.layerwise_pooling = LayerwiseWeightedSum(\n",
        "            num_layers=config.num_layers_to_average,\n",
        "            learnable=True\n",
        "        )\n",
        "\n",
        "        # Pooling strategy\n",
        "        if config.pooling_strategy == \"attention\":\n",
        "            self.attention_pooling = AttentionPooling(actual_hidden_size)\n",
        "\n",
        "        # Projection head\n",
        "        if config.use_projection_head:\n",
        "            self.projection_head = ProjectionHead(\n",
        "                input_dim=actual_hidden_size,\n",
        "                hidden_dim=config.projection_dim,\n",
        "                output_dim=config.projection_dim,\n",
        "                activation=config.activation,\n",
        "                dropout=config.dropout_rate\n",
        "            )\n",
        "\n",
        "    def _pool_embeddings(self, hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Apply pooling strategy\"\"\"\n",
        "        if self.config.pooling_strategy == \"cls\":\n",
        "            # Use CLS token (first token)\n",
        "            return hidden_states[:, 0, :]\n",
        "\n",
        "        elif self.config.pooling_strategy == \"mean\":\n",
        "            # Mean pooling with attention mask\n",
        "            input_mask_expanded = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
        "            sum_embeddings = torch.sum(hidden_states * input_mask_expanded, 1)\n",
        "            sum_mask = input_mask_expanded.sum(1)\n",
        "            sum_mask = torch.clamp(sum_mask, min=1e-9)\n",
        "            return sum_embeddings / sum_mask\n",
        "\n",
        "        elif self.config.pooling_strategy == \"attention\":\n",
        "            # Attention pooling\n",
        "            return self.attention_pooling(hidden_states, attention_mask)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown pooling strategy: {self.config.pooling_strategy}\")\n",
        "\n",
        "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
        "        # Get outputs from backbone\n",
        "        outputs = self.backbone(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Get last N layers\n",
        "        all_hidden_states = outputs.hidden_states\n",
        "        last_n_layers = all_hidden_states[-self.config.num_layers_to_average:]\n",
        "\n",
        "        # Apply layerwise weighted sum\n",
        "        weighted_hidden_states = self.layerwise_pooling(last_n_layers)\n",
        "\n",
        "        # Apply pooling\n",
        "        pooled_embeddings = self._pool_embeddings(weighted_hidden_states, attention_mask)\n",
        "\n",
        "        # Apply projection head if enabled\n",
        "        if self.config.use_projection_head:\n",
        "            embeddings = self.projection_head(pooled_embeddings)\n",
        "        else:\n",
        "            # Apply L2 normalization directly\n",
        "            embeddings = F.normalize(pooled_embeddings, p=2, dim=-1)\n",
        "\n",
        "        return embeddings"
      ],
      "metadata": {
        "id": "zcaJMImcjIun"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class STSBenchmarkDataset(Dataset):\n",
        "    \"\"\"STS Benchmark dataset for evaluation\"\"\"\n",
        "    def __init__(self, data_path: str, tokenizer, max_length: int = 512):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.data = self._load_data(data_path)\n",
        "\n",
        "    def _load_data(self, data_path: str):\n",
        "        \"\"\"Load STS benchmark data\"\"\"\n",
        "        # For demo purposes, creating synthetic data\n",
        "        # In practice, load from actual STS benchmark files\n",
        "        data = []\n",
        "\n",
        "        # Synthetic data for demonstration\n",
        "        samples = [\n",
        "            (\"The cat sat on the mat\", \"A cat was sitting on a mat\", 4.5),\n",
        "            (\"I love pizza\", \"Pizza is my favorite food\", 3.8),\n",
        "            (\"The weather is nice\", \"It's raining heavily\", 1.2),\n",
        "            (\"Machine learning is fascinating\", \"AI and ML are interesting topics\", 4.2),\n",
        "            (\"The dog ran quickly\", \"A fast dog was running\", 4.0),\n",
        "            (\"Books are educational\", \"Reading helps you learn\", 3.5),\n",
        "            (\"The sun is shining\", \"It's a cloudy day\", 1.8),\n",
        "            (\"Programming is fun\", \"Coding can be enjoyable\", 4.1)\n",
        "        ] * 100  # Repeat to create larger dataset\n",
        "\n",
        "        for sent1, sent2, score in samples:\n",
        "            data.append({\n",
        "                'sentence1': sent1,\n",
        "                'sentence2': sent2,\n",
        "                'score': score / 5.0  # Normalize to [0, 1]\n",
        "            })\n",
        "\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.data[idx]\n",
        "\n",
        "        # Tokenize sentences\n",
        "        encoding1 = self.tokenizer(\n",
        "            item['sentence1'],\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        encoding2 = self.tokenizer(\n",
        "            item['sentence2'],\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids_1': encoding1['input_ids'].squeeze(0),\n",
        "            'attention_mask_1': encoding1['attention_mask'].squeeze(0),\n",
        "            'input_ids_2': encoding2['input_ids'].squeeze(0),\n",
        "            'attention_mask_2': encoding2['attention_mask'].squeeze(0),\n",
        "            'score': torch.tensor(item['score'], dtype=torch.float)\n",
        "        }"
      ],
      "metadata": {
        "id": "Cdn3EsCajNF6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomBGETrainer:\n",
        "    \"\"\"Trainer for custom BGE model\"\"\"\n",
        "    def __init__(self, model: CustomBGEModel, tokenizer, device: str = \"cuda\"):\n",
        "        self.model = model.to(device)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.device = device\n",
        "\n",
        "    def compute_similarity_loss(self, embeddings1: torch.Tensor, embeddings2: torch.Tensor,\n",
        "                               scores: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute cosine similarity loss\"\"\"\n",
        "        # Compute cosine similarity\n",
        "        cos_sim = F.cosine_similarity(embeddings1, embeddings2, dim=-1)\n",
        "\n",
        "        # MSE loss between cosine similarity and ground truth scores\n",
        "        loss = F.mse_loss(cos_sim, scores)\n",
        "        return loss\n",
        "\n",
        "    def train_epoch(self, dataloader: DataLoader, optimizer, scheduler=None):\n",
        "        \"\"\"Train for one epoch\"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for batch_idx, batch in enumerate(dataloader):\n",
        "            # Move to device\n",
        "            for key in batch:\n",
        "                batch[key] = batch[key].to(self.device)\n",
        "\n",
        "            # Forward pass\n",
        "            embeddings1 = self.model(batch['input_ids_1'], batch['attention_mask_1'])\n",
        "            embeddings2 = self.model(batch['input_ids_2'], batch['attention_mask_2'])\n",
        "\n",
        "            # Compute loss\n",
        "            loss = self.compute_similarity_loss(embeddings1, embeddings2, batch['score'])\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if scheduler:\n",
        "                scheduler.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if batch_idx % 50 == 0:\n",
        "                logger.info(f\"Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "        return total_loss / len(dataloader)\n",
        "\n",
        "    def evaluate(self, dataloader: DataLoader) -> Dict[str, float]:\n",
        "        \"\"\"Evaluate model performance\"\"\"\n",
        "        self.model.eval()\n",
        "        predictions = []\n",
        "        ground_truth = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in dataloader:\n",
        "                # Move to device\n",
        "                for key in batch:\n",
        "                    batch[key] = batch[key].to(self.device)\n",
        "\n",
        "                # Forward pass\n",
        "                embeddings1 = self.model(batch['input_ids_1'], batch['attention_mask_1'])\n",
        "                embeddings2 = self.model(batch['input_ids_2'], batch['attention_mask_2'])\n",
        "\n",
        "                # Compute cosine similarity\n",
        "                cos_sim = F.cosine_similarity(embeddings1, embeddings2, dim=-1)\n",
        "\n",
        "                predictions.extend(cos_sim.cpu().numpy())\n",
        "                ground_truth.extend(batch['score'].cpu().numpy())\n",
        "\n",
        "        # Compute Spearman correlation\n",
        "        spearman_corr, _ = spearmanr(predictions, ground_truth)\n",
        "\n",
        "        # Compute MSE\n",
        "        mse = np.mean((np.array(predictions) - np.array(ground_truth)) ** 2)\n",
        "\n",
        "        return {\n",
        "            'spearman_correlation': spearman_corr,\n",
        "            'mse': mse,\n",
        "            'predictions': predictions[:10],  # First 10 predictions for inspection\n",
        "            'ground_truth': ground_truth[:10]  # First 10 ground truth for inspection\n",
        "        }"
      ],
      "metadata": {
        "id": "ZB9Us4qqjadJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Main training and evaluation pipeline\"\"\"\n",
        "# Configuration\n",
        "config = ModelConfig(\n",
        "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
        "    projection_dim=768,\n",
        "    num_layers_to_average=4,\n",
        "    pooling_strategy=\"mean\",  # Try \"cls\", \"mean\", or \"attention\"\n",
        "    use_projection_head=True,\n",
        "    dropout_rate=0.1,\n",
        "    activation=\"gelu\"\n",
        ")\n",
        "\n",
        "# Initialize tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
        "model = CustomBGEModel(config)\n",
        "\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NY0M9t-Nj2dz",
        "outputId": "4c8fd879-d073-4b27-85ad-ec141472236d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 34,246,276\n",
            "Trainable parameters: 34,246,276\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "train_dataset = STSBenchmarkDataset(\"train.tsv\", tokenizer)\n",
        "val_dataset = STSBenchmarkDataset(\"dev.tsv\", tokenizer)\n",
        "\n",
        "# Create dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Initialize trainer\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "trainer = CustomBGETrainer(model, tokenizer, device)"
      ],
      "metadata": {
        "id": "FlauYIEGj7Ex"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup optimizer and scheduler\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "num_training_steps = len(train_dataloader) * 3  # 3 epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0.1 * num_training_steps,\n",
        "    num_training_steps=num_training_steps\n",
        ")"
      ],
      "metadata": {
        "id": "i6cQ9lh9kASW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "best_correlation = -1\n",
        "for epoch in range(3):\n",
        "    logger.info(f\"Epoch {epoch + 1}/3\")\n",
        "\n",
        "    # Train\n",
        "    train_loss = trainer.train_epoch(train_dataloader, optimizer, scheduler)\n",
        "    logger.info(f\"Training loss: {train_loss:.4f}\")\n",
        "\n",
        "    # Evaluate\n",
        "    eval_results = trainer.evaluate(val_dataloader)\n",
        "    logger.info(f\"Validation results: {eval_results}\")\n",
        "\n",
        "    # Save best model\n",
        "    if eval_results['spearman_correlation'] > best_correlation:\n",
        "        best_correlation = eval_results['spearman_correlation']\n",
        "        torch.save(model.state_dict(), 'best_custom_bge_model.pt')\n",
        "        logger.info(f\"New best model saved! Spearman correlation: {best_correlation:.4f}\")"
      ],
      "metadata": {
        "id": "ag-7H3C4kGpV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test different configurations\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"TESTING DIFFERENT CONFIGURATIONS\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "configs_to_test = [\n",
        "    {\"pooling_strategy\": \"cls\", \"name\": \"CLS Pooling\"},\n",
        "    {\"pooling_strategy\": \"mean\", \"name\": \"Mean Pooling\"},\n",
        "    {\"pooling_strategy\": \"attention\", \"name\": \"Attention Pooling\"},\n",
        "    {\"use_projection_head\": False, \"name\": \"Without Projection Head\"},\n",
        "    {\"num_layers_to_average\": 6, \"name\": \"6 Layer Average\"}\n",
        "]\n",
        "\n",
        "base_config = ModelConfig()\n",
        "results = {}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89EJplTukI1E",
        "outputId": "daf3430a-057e-402a-ffae-b04b02aa8a5c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "TESTING DIFFERENT CONFIGURATIONS\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for test_config in configs_to_test:\n",
        "    print(f\"\\nTesting: {test_config['name']}\")\n",
        "\n",
        "    # Create new config\n",
        "    new_config = ModelConfig(**{**base_config.__dict__, **{k: v for k, v in test_config.items() if k != 'name'}})\n",
        "\n",
        "    # Create and evaluate model\n",
        "    test_model = CustomBGEModel(new_config)\n",
        "    test_trainer = CustomBGETrainer(test_model, tokenizer, device)\n",
        "\n",
        "    # Quick evaluation (no training)\n",
        "    eval_results = test_trainer.evaluate(val_dataloader)\n",
        "    results[test_config['name']] = eval_results['spearman_correlation']\n",
        "    print(f\"Spearman Correlation: {eval_results['spearman_correlation']:.4f}\")\n",
        "\n",
        "# Print summary\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"CONFIGURATION COMPARISON\")\n",
        "print(\"=\"*50)\n",
        "for name, correlation in results.items():\n",
        "    print(f\"{name}: {correlation:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be9EIdMojaaN",
        "outputId": "7e8d1d62-4c46-4492-9946-b5b21559cd72"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing: CLS Pooling\n",
            "Spearman Correlation: 0.2619\n",
            "\n",
            "Testing: Mean Pooling\n",
            "Spearman Correlation: 0.4048\n",
            "\n",
            "Testing: Attention Pooling\n",
            "Spearman Correlation: 0.2857\n",
            "\n",
            "Testing: Without Projection Head\n",
            "Spearman Correlation: 0.3810\n",
            "\n",
            "Testing: 6 Layer Average\n",
            "Spearman Correlation: 0.2857\n",
            "\n",
            "==================================================\n",
            "CONFIGURATION COMPARISON\n",
            "==================================================\n",
            "CLS Pooling: 0.2619\n",
            "Mean Pooling: 0.4048\n",
            "Attention Pooling: 0.2857\n",
            "Without Projection Head: 0.3810\n",
            "6 Layer Average: 0.2857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MB5Y3R8OjaXd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}